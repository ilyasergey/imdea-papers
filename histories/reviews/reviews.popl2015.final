===========================================================================
                            popl15 Review #68A
                     Updated 5 Aug 2014 11:29:25pm EDT
---------------------------------------------------------------------------
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                   ===== Comments for the Authors =====

This paper presents a Hoare-style approach to specifying and verifying fine-grained
concurrent algorithms and data-structures. The essential idea is to encode the notion
of a "history" directly into the specification. Thus, the pre-conditions and post-conditions
in the logic make use of the histories (in place of just state). This leads to what is
arguably a more natural and intuitive specification (e.g., close in spirit to linearizability-based
approaches).

The paper shows how the recently proposed FCSL (Fine-grained Concurrent Separation Logic) can
be used to achieve this. The paper draws an analogy between the treatment of heap by Separation
Logic and the treatment of histories, which is quite interesting and is the basis for the
approach presented in the paper.

The paper mostly illustrates the idea and approach by applying it to three examples.

Overall, this is interesting. I like the general presentation style of using examples to
illustrate the ideas and approach, keeping it concrete and grounded. But I think there is still
some room for improvement in the presentation, especially in the beginning (section 2).

Other Comments:

* The paper tries too hard in the first page to argue the advantages of the proposed
approach over the notion of linearizability. This is not quite convincing and may be needless.
In fact, it would be more convincing if the paper were to show how non-linearizable (with
respect to simple or standard data-structure semantics) libraries can be handled using
the proposed approach.

* It would help to clarify upfront what a PCM is ... in particular, to explain what
assumptions are made about when the "partial" operator is defined. Furthermore, section
2 uses the disjoint-union operator on histories. What happens if the disjoint-union
of two histories produces one that is not "continuous"?

* The specification (equation (5)) and explanation in section 2 are a bit confusing.
In particular, the specification looks as though it is a partial one as it only
considers the case where the self-history is empty. There is a claim that the frame
rule allows generalizing it to the case where the self-history is not empty. (This
is illustrated later in the end of section 3.1.) This appears to be a bit magical,
Presumably the magic is buried in the PCM structure / FCSL. 

It might be simpler to first illustrate the (apparently) more-complete specification
(equation (16)) first, and discuss (5) and the frame-rule later on.

It might also help to use different symbols for tau_0 in the precondition and postcondition
of (5) to stress that they could be different. 

The use of tau to make (5) "stable" also makes it a bit harder to understand first.

===========================================================================
                            popl15 Review #68B
                    Updated 26 Aug 2014 11:42:17am EDT
---------------------------------------------------------------------------
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                   ===== Comments for the Authors =====

SUMMARY

The paper addresses the question: how, in a suitable concurrent separation
logic, can one assign a satisfactory specification to a fine-grained
concurrent data structure (and prove that this specification is indeed
satisfied by the implementation)?

The paper begins with the remark that histories (viewed as sets of pairs of a
timestamp and an action) are very much like heap fragments (which are sets of
pairs of an address and a value). In particular, histories form a partial
commmutative monoid (PCM), which means that the usual tools of separation
logic can be used to reason about histories. In fact, there are several recent
variants of separation logic where the user can allocate auxiliary state and
equip it with a PCM of their choosing. This means that modular reasoning about
histories comes for free, in a sense.

The paper chooses to use FCSL as an off-the-shelf logic in which reasoning
with histories is possible. FCSL incorporates "subjectivity", which in short
means that each thread has its own view of the auxiliary state, and is able
to make assertions about both its own view (the "self" component) and about
the other thread's view (the "other" component). FCSL also allows shared
state (the "joint" component), and the evolution of these three components
is governed by a protocol (a "concurroid") that is fixed beforehand. The
assertions used in an FCSL proof must be provably stable with respect to
this protocol.

The paper provides three examples of how FCSL and histories can be used.

One (Section 2) is a simple pair-snapshot data structure and serves as a
motivating example.

The second example (Section 4) is Treiber's stack, for which the paper
establishes a history-based specification. The paper uses FCSL's "hide" rule
to prove that the sequential spec of stacks is a special case of it (which
means that if Treiber's stack is privately owned by just one thread, then it
behaves like a sequential stack). Section 4 also gives a typical example of
concurrent client-side reasoning, a producer/consumer example. The proof
involves interesting loop invariants (which refer to the history of each
participant) plus "hiding" (which intuitively argues that the stack is private
to this particular producer/consumer pair, hence there is no outside
interference).

The last and most complex example is Hendler et al.'s flat combiner (Section
5), whose specification is higher-order. In addition to specifying and proving
the algorithm, there is a little bit of client-side reasoning (Section 5.4),
where the "push" method of a sequential stack is invoked inside "flatCombine",
and the resulting spec is (roughly) the same as that of "Treiber-push" -- i.e.
both approaches are correct ways of implementing a concurrent stack, and the
client reasons in the same way about them.

The proofs are machine-checked.

EVALUATION

The introduction (Section 1) and the motivating example (Section 2) are very
well written, in my opinion. The idea that histories should be equipped with
PCM structure, so that an off-the-shelf separation logic can be used to reason
about histories, without requiring any ad hoc extension, seems natural and
compelling.

The basic intuitions of subjectivity (i.e., "self" versus "other" views of the
auxiliary state) seem relatively simple, and it is a good thing that an
existing logic (here, FCSL) is used off-the-shelf. That said, FCSL itself
seems extremely complex. Even though I have (once) read the FCSL paper before,
I find it difficult to really understand the material in section 3, especially
the abstract reasoning rules in Section 3.3. Also, even though the proof
outline in Section 2 seems very simple, some details are really swept under
the rug and deferred until Section 3, where the "pair-snapshot concurroid" is
defined. I have some difficulty understanding the big picture; in particular
Section 2 works with Hoare triples, but Section 3 works with quadruples
{P}c{Q}@U, where U is a concurroid. I wish this was better explained,
especially as far as client-side reasoning is concerned.

Section 4 seemed quite interesting to me.

Section 5 I believe should be interesting, but seemed overwhelming to me as a
non-expert. If I understand correctly, the method flatCombine(f,x) is supposed
to have the same spec as the equivalent coarse-grained implementation,
lock();f(x);unlock(). But the specifications of lock() and unlock() are not
given (they are sketched in a brief and informal manner). That's too bad; I
would have liked to see the specification and proof outline for the
coarse-grained implementation, before delving into the details of the
fine-grained implementation.

The fact that the proofs are machine-checked is quite important in my eyes.
It would be all too easy to get the details wrong otherwise.

In summary, on the positive side, this seems to be an impressive, and quite
elegant piece of work.  There is no new, ad hoc extension of concurrent
separation logic; the work is carried out in the setting of an existing logic,
FCSL. Perhaps other separation logics that support user-defined PCMs could be
used as an alternative foundation? The three examples that are developed are
non-trivial and quite complete (specification, proof, and client-side
reasoning).

On the negative side, the logic FCSL seems quite complex. Its rules require
serious study by the reader. Also, its treatment of private state seems
somewhat strange to me, as it relies on assertions of the form pv |-> h, where
h is an explicit heap, and this approach seems to require giving up the usual
benefits of separation logic, where the heap is never explicitly named, and is
instead described by an assertion. I don't know why the private heap is
described in this manner. In summary, one may wish for a simpler foundation to
be adopted in the future.

The paper seems to make an interesting contribution (backed up by
machine-checked proofs) and I believe it should be accepted.

COMMENTS FOR THE AUTHORS

p.1, second column, "for a class of structures": not sure what this means.
Does "structure" mean "data structure"?

p.1, "granularity abstraction": this term has not been defined. I assume
it refers to the idea (explained above) that the client can reason about
a fine-grained implementation as if it was coarse-grained.

p.2, "histories form a PCM with disjoint union": I assume a history is a
*sequence* of actions, not a set of actions. So, what does "disjoint union"
mean for histories? Oh, wait. I suppose a history is a *set* of timestamped
actions. Then, disjoint union makes sense. Could this be clarified?

p.2, "Histories [...] are finite maps from the natural numbers to [...]". Is
it obvious that using natural numbers for timestamps is a good choice (or the
only choice)? Natural numbers are equipped with the successor operation,
which leads you to require "continuity". Would it make sense to use an
abstract type of timestamps that does not support successor?

p.2, your explanation of the atomic pair snapshot data structure initially
looks as if the x and y components are treated in a symmetric manner; but
actually, the code in Figure 1 relies solely on the version number vx; it
looks as if vy is completely unused. Equation (4) seems to confirm this. Is
it indeed the case that vy is unused? Or is it used by some other method?

p.2, "Thus, histories only grow, and only by adding valid snapshots". What
does "valid" mean here? What would be an invalid snapshot?

p.3, "Inclusion makes the precondition stable [...]": more generally, is there
an obligation to check that every assertion in Figure 2 is stable?  (I assume
there is.) But then, stable with respect to what? I suppose the answer is,
stable with respect to a suitable concurroid, which is hidden here (for
simplicity) and will be explained in Section 3. Perhaps this should be said.

p.3, "The readX method has the following spec:" Perhaps you could spend a
couple lines explaining this spec? In particular I wasn't quite sure why
"tau <= t" in the postcondition makes intuitive sense (I guess a suitable
witness for t is the most recent timestamp in the input history tau_O).

Figure 2, line 7, I like the way in which tau_1 no longer appears in this
assertion, as it is subsumed by tau_2, which is a richer history. Nice.

p.4, "labeled components". When a history is identified by a label l, one
could think of the history as stored in a ghost memory cell whose address is
l. Thus, instead of saying that l is a "label", you could say it is a "ghost
memory location". (Some authors have also used the words "region" or "island"
for a piece of ghost state identified by a unique address.)

p.4, "The self and other portions of any given label have to belong to a
common PCM". What about the joint portion? Does it also have to belong to some
PCM?

p.4, "different labels can use different PCMs". So the points-to assertions
are implicitly parameterized with a PCM?

p.4, "These three basic assertions can be combined by the usual propositional
connectives [...]". Why does it make sense here to use ordinary conjunction
instead of separating conjunction?

p.5, in the definition of "wr_x", the "other history" tau_O seems to appear
out of nowhere (I mean, there is one occurrence of the metavariable tau_O,
but it is not constrained by an assertion l |->^O tau_O). Puzzling.

Section 3.3 is really quite cryptic, even if the reader has read the FCSL
paper before (I have).

One thing that isn't clear to me at the end of Section 3 is that there is
a certain mismatch between Sections 2 and 3. Throughout Section 2, triples
of the form {P}c{Q} are used. Now, Section 3 reveals that in FCSL, triples
really are quadruples of the form {P}c{Q}@U. So I assume Section 2 must be
revisited with the idea that every triple in it is implicitly relative to
the pair-snapshot concurroid, called "S" in the paper. Thus, the "real"
spec of readPair is of the form {...} readPair() {...} @ S. Now, if I am
a client who wishes to use readPair(), how much do I need to know about S?
Do I need to have access to its concrete definition? (Hopefully not, since
it reveals implementation details of the pair-snapshot data structure.) Do
I need to treat S as an "abstract concurroid" whose definition is opaque?
Or can I somehow "hide" S and perform my client-side reasoning in the empty
concurroid? I wish this was clarified.

p.6, "Note that pop doesn’t deallocate [...]". If you modified the code of
pop() to deallocate the node p, would your proof break? (I hope it would!)
Where/why would it break? Is this explained later on in the paper? My guess is
that 1- the Treiber concurroid doesn't allow deallocation (as noted in the
paper); 2- if pop() used deallocate(), then its spec would need to mention
P-entangled-T instead of just T; 3- but then certain assertions that appear in
its proof would no longer be stable (not sure why).

p.6, in the definition of the Treiber concurroid, why is the shared heap h_s
described explicitly (i.e. as a union of several sub-heaps) instead of via a
separation logic assertion (i.e. as a separating conjunction of several
predicates, one for each sub-heap)? We seem to be losing some of the usual
benefits of separation logic here. We end up using a first-order logic
predicate list(p, l, h) instead of the usual separation logic predicate
list(p, l).

Similarly, why does (26) on p.7 define Arr_n(a,l,h), instead of
separation-logic predicate Arr_n(a,l)?

And why do we have to write "pv \mapsto^s h" instead of just writing
a normal separation logic assertion that describes our private state?
Again, we seem to be losing some readability (and compatibility with
standard separation logic). Could this situation be improved?

p.6, why does completeness (no gaps in the history) not appear also in the
pair-snapshot example? I suppose it is not necessary there.

Figure 4, the proof is clear, except of course the reader would like to
know how one proves that tryPush admits this specification.

p.7, "which is essentially an elaborated version of (1)". Perhaps you
could introduce grb also in the precondition, and then argue that, up
to an appropriate definition of the "abstract points-to" predicate that
appears in (1), we *really* obtain (1).

p.8, "Note also that the sentinel pointer is returned back to the private
heap, along with the garbage heap". This seems a little too concrete in
my eyes. Ideally I would like the proof of "exchange" to be independent
of the implementation of Treiber's stack -- hence the client should not
know that there is a sentinel pointer, a garbage heap, etc. It should
only reason in terms of an abstract predicate that describe a Treiber
stack. Could you do this? I suppose you can (but the module Treiber needs
to export an operation new_stack() in addition to push() and pop()).

p.8, "To supply the intuition behind the proof, we first review how ordinary
locks work with auxiliary state [...]". Could you explicitly give the Hoare
triples (or quadruples) for lock and unlock? The informal description that
follows is difficult to understand.

p.8, you write "As in CSL [...]  a lock comes with a resource invariant I
which relates the auxiliary state to the heap of the shared resource". But
in CSL, I is just an assertion, which describes the shared resource, period.
There is no built-in idea of an "auxiliary state" in the reasoning rules for
locks, is there?

If one were to implement coarseGrainedCombine(f, x) simply as a sequence
of lock();f(x);unlock(), would one be able to prove exactly the same
abstract specifications for coarseGrainedCombine and flatCombine?

Footnote 7 on page 9 is cryptic. Exactly what kind of side effects is the
function f allowed to perform? Can it alter some private state? Can it use
concurrent data structures (other than the flat combiner at hand)? etc.
I am somewhat lost.

p.9, "The spec for flatCombine is given wrt. a specific thread id tid".
You seem to assume tid is a thread-local variable (i.e. each thread has
its own tid). Ideally one should explain how a new flat combiner is
initialised, how each participating thread receives its own tid and
its own proof of NoReq(tid). Ideally this machinery should be somehow
abstracted away inside the FC module, which would provide only two
operations new_flat_combiner() and flatCombine(fc, f, x)...
(Of course the paper is complex enough as it stands. This is just a
suggestion for future work...)

TYPOS

p.2, "We consider atomic pair snapshot data structure" (singular? plural?)

p.2, "Treiber stack" -> "Treiber's stack" or "a Treiber stack"?

p.2, "we illustrate history-based specification by applying them"

p.3, "it must be t1 <= t2" -> "it must be that t1 <= t2"? (same idiom elsewhere)

p.3, "Such restriction" -> "Such a restriction"

p.4, "If the type used by some label is non-heap, than that label" -> "then"

p.4, "the calling threads has"

p.4, "The concurroids thus bound the moves of the concurrent programs that
operates on a data structure" -> "operate"?

p.6, "times-tamps" (strange hyphenation?)

p.11, "One can choose arbitrary datatype"

===========================================================================
                            popl15 Review #68C
                     Updated 22 Sep 2014 9:38:53am EDT
---------------------------------------------------------------------------
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: X. I am an expert in this area

                   ===== Comments for the Authors =====

This paper presents a logic for reasoning about concurrent programs
using histories.  It builds on previous work [19,22] and instantiates
it with a PCM for histories.  


As far as I can see the only real contribution of this paper is a that
it presents a PCM (Partial Commutative Monoid) that represents
histories.  That this is exists is hardly surprising: auxiliary state
has been used to represent histories since its uses by Owicki/Gries
for proving completeness, and the earlier work [19] claims "subjectivity"
generalises auxiliary state.  The precise definition you provide is
new and interesting, but doesn't merit a whole POPL paper. 


You claim that you provide granularity abstraction.  But this seems a
pretty lightweight intrepretation of that.  In fact, when you compare
to TaDA you say future work is allowing make_atomic apply to commands
with a single logical action.  

It wasn't clear to me that you specs improve on iCAP/HOCAP in terms
granularity abstraction either.  They present one spec that can be
specialised to the obvious sequential spec, and also to the
specification you give in the introduction (2). [Note this is allowing
the client to specify the spec, not as you claim a necessary
restriction on all clients].  Can you provide one spec that is that
general?  You show you can specialise to the sequential spec, but not
to (2).

Ultimately it seems to me the granularity abstraction you present is
just the standard abstraction provided by auxiliary variables. It is
nicely packaged with previous work [19].


I probably would have read this paper more favourably, if it had been
clear that you aren't getting as much granularity abstraction as
CaReSL/Jacobs[17]/HOCAP/iCAP/TaDA/L&F, but pitch the level you got as good
enough, and make a case for that.  As it stands you are overselling,
and delivering less than the other approaches.



[POST REBUTTAL ADDITIONS]

Re Overselling.  I agree that Section 6 provides an accurate comparison.  My main concern is two parts of the introduction, which set the tone for the paper:

(1) In the first column of the paper you say
  "a few recent proposals ... [restrict] the stack elements to satisfying a fixed client-chosen predicate P."
Firstly, I think this statement is incorrect.  Second, it implies you are going to do better than the specifications given in those works, which I don't believe you do for the stack.


(2) The term "granularity abstraction" is used repeatedly, but it implies more to me, than you deliver.  You are not providing any granularity abstraction beyond what is delivered by most of the previous work.  And with regard to CaReSL/Jacobs[17]/HOCAP/iCAP/TaDA/L&F you are delivering less  "granularity abstraction".  Your abstraction is simply pre- and post-condition reasoning with abstraction of the internal state.  That abstraction is elegantly done with the PCM for histories.  I would have been much happier if the paper was pitched without granularity abstraction.  


Re ReadPair:  I am unsure why you think this can not be done in iCAP.  Jacobs original idea was simply to associate an parameterised "auxiliary" update with certain atomic actions of the program that typically correspond to linearization points.  My understanding is this is the same as in iCAP, just they use a "view shift" instead.  A view shift is just a change in "view" where the underlying state is unchanged and all contexts are preserved.  So I can not see why you think it requires a state change.  The iCAP setup has some step-indexes that must move to do a lot of stuff, but a read creates a step as far as I know.


Re Histories PCM:  It would be useful to compare your approach to 

Christian J. Bell, Andrew W. Appel, and David Walker. 2010. Concurrent separation logic for pipelined parallelization.

As they build a PCM of histories for reasoning about channels.  


Summary
-------
Overall, I think the histories PCM you use is cute and leads to some nice specs.  I think you need to drop the claims for granularity abstraction as I don't think you really deliver on them.

===========================================================================
                            popl15 Review #68D
                     Updated 30 Aug 2014 3:27:53am EDT
---------------------------------------------------------------------------
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                   ===== Comments for the Authors =====

This paper adds the notion of histories to a concurrent separation logic to enable atomic action specifications of concurrent data structures.  The paper observes that histories satisfy the same mathematical structure that heaps in traditional separation logic do.  As a result, concepts such as framing and ownership transfer can be transferred to histories to simplify proofs.  Am implementation has been done by embedding a simple imperative programming language into Coq.  Two case studies, Treiber stack and its client and a flat combiner lock,
have been proven using Coq.

Histories sound like a good thing to add to enable reasoning about atomic actions and to separate client-side reasoning from that about the implementation of the concurrent data structure.  The observations regarding the correspondence between heaps and histories is also interesting.  But, despite the authors' claim to the contrary, the approach feels heavyweight to me.  The two case studies, although tricky, are small and do not give a good sense of proof automation and scalability of the methodology to larger concurrent programs. On balance, I am positive because the ability to reason with atomic specifications seems fundamentally important.  Also, the authors did enough implementation to push two examples through.

===========================================================================
                            popl15 Review #68E
                     Updated 18 Sep 2014 8:58:13pm EDT
---------------------------------------------------------------------------
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: X. I am an expert in this area

                   ===== Comments for the Authors =====

Below are the detailed comments about pros and cons of the paper.

Pros:
1) The writing is nice. The paper is easy to read. Explanations of technical details are easy to follow.
2) The paper shows the marriage of histories and subjectivity in CSL style logic. Although nether histories nor subjectivities (in FCSL) is new, it’s not a trivial job to introduce histories in concurrency reasoning. In particular, one needs to distinguish in the traces actions made by the current threads and those made by the environments. The idea of subjectivity makes the distinction natural and neat. The use of explicit timestamps t in histories also helps to make histories PCM (partial commutative monoid).
3) Verification of some algorithms (e.g., the atomic pair snapshot algorithm which requires speculation in earlier work, and the flat combining algorithm that requires helping) becomes simpler.
4) The work has been mechanized in Coq (I didn't check the Coq code though).

Cons:
1) The work is a bit incremental in that it is just an extension of FCSL with richer assertions. There is no new program logics proposed. Also there are no new examples verified (all examples have been verified before in various papers), which means it’s unclear if the paper verifies algorithms that cannot be verified before.
2) The simplicity of the verification of algorithms by using histories is a bit deceiving. The use of histories (in this paper and previous works [10,12]) essentially collect program behaviors in the temporal assertions, and then do non-local reasoning based on the temporal assertions. In some sense, the work shifts the verification burden from local reasoning in Hoare logic rules to non-local reasoning at the assertion level (e.g., proofs for Lemma 4.1 and 4.2, and the properties (i), (ii) and (iii) for the pair snapshot algorithm in pages 2 and 3). Here by being non-local, I mean it’s temporally non-local because the reasoning is based on execution traces instead of on the current program states and the current command only. Since now we can specify and verify the properties based on execution traces, of course the specs and verification look simpler. But the proof obligations at the assertion level are more difficult to discharge.
3) The semantics of assertions and Hoare logic judgments, and the soundness of the program logic are not shown in the paper.

===========================================================================
              Response by Ilya Sergey <ilya.sergey@imdea.org>
   Paper #68: Specifying and Verifying Fine-Grained Concurrent Algorithms
              with Histories and Subjectivity
---------------------------------------------------------------------------
We thank the reviewers for feedback and respond to their main
concerns.

===[#68A]===

[Are non-linearizable libraries handleable?]

Yes. The flat-combiner example isn't linearizable in the traditional
sense. Recent work [3] had to generalize linearizability to support
flat-combiner.

===[#68B]=== 

[Abstract over concurroids?]

The Coq embedding of FCSL is integral to the paper and provides for
free the ability to abstract over any semantic category, including
values, types, predicates, and certainly concurroids. Such abstraction
has been done for locks (see Appendix E5 of [22]'s extended
version). Thus, we believe we could give a general spec for stacks,
though we haven't done that yet.

[Use separating conjunction?]

It's non-trivial to scale SL notation to concurrency in general. The
usual approach initiated by RGSep [33] includes a modality for shared
state. With subjectivity, we would also require a modality for "other"
state, and a number of laws relating modalities with other assertion
connectives. This makes everything a bit heavy. Instead, we chose to
stick with explicit heap (or general PCM) variables. Working with heap
variables *is* pleasant, and has to be done in Coq anyway, since Coq
lacks support for BI contexts. This has been argued before in
[Nanevski, Vafeiadis, Berdine (POPL'10)].

===[#68C]===

[Overselling, delivering less.]

Nowhere do we promote FCSL as being more expressive than the related
works CaReSL/Jacobs[17]/HOCAP/iCAP/TaDA/L&F. In Section 6 we clearly
mention that we don't provide the same granularity abstraction as
TaDA/iCAP. We've even sketched how relying on prime PCM elements will
scale to overcome the limitation. So we're puzzled by the
"overselling" comment. For more on how to get a form of (2), see
below.

We disagree that the current limitation implies that our approach is
"delivering less". There're things we can't do, but others can, and
vice versa. For example, iCAP is the most developed of the existing
logics, but it's our understanding that it can't currently express the
spec for readPair similar to ours, because readPair doesn't change the
state (and a change apparently is required by the viewshift
mechanism).

[The paper presents a logic...]

As we have clearly stated, our paper is not about a new logic, but
about a new specification method based on the observation that
histories are PCMs, just like heaps. We expect the method will be
useful to other logics, independent of their expressiveness, but they
will have to be extended with subjectivity. We chose FCSL because it
was most convenient for us.

[Observation about histories is "hardly surprising"...]

Contrarily, we find it very surprising that histories *with
subjectivity* suffice to produce simple, general, and novel specs and
proofs of quite interesting programs. As of now, we haven't needed
code-as-resources, tokens, fractional permissions,
permission-dependent actions, view-shifts, speculations, etc., which
all add bulk to concurrency logics. Simple PCMs and subjectivity
sufficed to unify FCSL to the extent that proofs of example programs
could be mechanized. This is crucial to build confidence in a
logic. None of the related systems has been sufficiently optimized to
do the same (at best, they mechanize meta-theory only).

===========================================
The rest of this response answers the reviewers' specific questions.
===========================================

===[#68A]===

> It would help to clarify upfront what a PCM is ... in particular, to
> explain what assumptions are made about when the "partial" join
> operator is defined.

Definition of a PCM employed for carrying out the necessary invariants
is up to the client [22]. In our studies the PCM employed included
natural numbers (with plus), heaps (with disjoint union), mutual
exclusion PCM (defined in Section 5.1) and histories (with disjoint
union, again). Partiality models impossible combinations of threads'
contributions to the resource. For instance, in the mutual exclusion
PCM, the result of joining two 'Own' elements is undefined, which
models a situation that a lock cannot be held by more than one
concurrent thread simultaneously.

> Furthermore, section 2 uses the disjoint-union operator on
> histories. What happens if the disjoint-union of two histories
> produces one that is not "continuous"?

The notion of history continuity is orthogonal to the PCM axioms, and
it is enforced as an invariant of the concurroid STS in each of the
examples. While not important for the verification of the pair
snapshot, it has been proven to be useful to reason about data
structures, such as stacks, allowing us to specify the freedom from
the ABA problem (page 6) and to verify the sequential specification. 

All concurroids presented in the paper ensure that the combined
self/other histories captured by them are continuous and remain so as
they evolve via transitions.

> The specification (equation (5)) and explanation in section 2 are a
> bit confusing.  In particular, the specification looks as though it
> is a partial one as it only considers the case where the
> self-history is empty. There is a claim that the frame rule allows
> generalizing it to the case where the self-history is not
> empty. (This is illustrated later in the end of section 3.1.) This
> appears to be a bit magical, Presumably the magic is buried in the
> PCM structure / FCSL.  It might be simpler to first illustrate the
> (apparently) more-complete specification (equation (16)) first, and
> discuss (5) and the frame-rule later on.

By presenting the specification with the empty self-history, we follow
the tradition of separation logic, in which programs are usually given
the "tightest" possible spec, i.e., specs mention the smallest
possible heap necessary for the program to be executed (so-called
"small footprint"). Similarly, here we give the spec with a "small
footprint" in terms of history and, later, show how an *equivalent*
"large-footprint" spec can be derived using frame rule, which in FCSL
generalizes the traditional separation logic rule for heaps to
arbitrary PCMs [22].

> The use of tau to make (5) "stable" also makes it a bit harder to
> understand first.

We agree that the spec (5) can be simplified, but at the price of
losing the knowledge that the snapshot captured by readPair (at a
timestamp 't') actually took place during the readPair execution
period (hence, \tau <= t in the postcondition).

===[#68B]===

> p.1, second column, "for a class of structures": not sure what this means.
> Does "structure" mean "data structure"?

Yes, indeed, "data structures" were meant.

> p.1, "granularity abstraction": this term has not been defined. I assume
> it refers to the idea (explained above) that the client can reason about
> a fine-grained implementation as if it was coarse-grained.

Unfortunately, there is no formal definition of granularity
abstraction in the literature.  We effectively reuse an informal
definition from Turon et al. [30]: "clients can pretend, for the
purpose of simplifying their own verification, that they are using the
coarse-grained version, yet be sure that their code will still be
correct when linked with the fine-grained version". We've
substantiated exactly this point with the producer/consumer client.

> p.2, "histories form a PCM with disjoint union": I assume a history is a
> *sequence* of actions, not a set of actions. So, what does "disjoint union"
> mean for histories? Oh, wait. I suppose a history is a *set* of timestamped
> actions. Then, disjoint union makes sense. Could this be clarified?

Your understanding is correct. We will clarify this in a future
revision.

> p.2, "Histories [...] are finite maps from the natural numbers to [...]". Is
> it obvious that using natural numbers for timestamps is a good choice (or the
> only choice)? Natural numbers are equipped with the successor operation,
> which leads you to require "continuity". Would it make sense to use an
> abstract type of timestamps that does not support successor?

Natural numbers were certainly an obvious choice, and we believe that
other choices are possible. However, without the ordering relation on
timestamps it would be tricky or even impossible to express the fact
that the "result" of the operation was logically observed during the
time-span of a corresponding procedure call (as it's done, e.g., in
the spec (5) via the inequality "\tau <= t"). As mentioned in Section
6, in the future we plan to consider branching-time histories, which
might employ different sets for time-stamping.

> p.2, your explanation of the atomic pair snapshot data structure initially
> looks as if the x and y components are treated in a symmetric manner; but
> actually, the code in Figure 1 relies solely on the version number vx; it
> looks as if vy is completely unused. Equation (4) seems to confirm this. Is
> it indeed the case that vy is unused? Or is it used by some other method?

Indeed, the structure is not treated symmetrically, so maybe
presenting the implementation in a symmetric way was
misleading. Ultimately, we had our eyes on the n-snapshot algorithm,
where one can have n pointers, and then the symmetry is required.

> p.2, "Thus, histories only grow, and only by adding valid snapshots". What
> does "valid" mean here? What would be an invalid snapshot?

Valid snapshot is one that corresponds to some particular values of
'x' and 'y' such that they were present in the data structure at the
same moment of time.

> p.3, "Inclusion makes the precondition stable [...]": more generally, is there
> an obligation to check that every assertion in Figure 2 is stable?  (I assume
> there is.) But then, stable with respect to what? I suppose the answer is,
> stable with respect to a suitable concurroid, which is hidden here (for
> simplicity) and will be explained in Section 3. Perhaps this should be said.

Indeed, each assertion is stable with respect to the environment
transitions described by the appropriate concurroid implementing a
protocol followed by a concurrent data structure.

However, one only needs to prove stability when applying rules for
atomic actions, frame, return and injection (see Fig 11 of the
Appendix). In general, there's no formation requirement of stability
on the assertions in a Hoare spec. Simply, if they aren't stable, the
spec won't be provable.

> p.3, "The readX method has the following spec:" Perhaps you could spend a
> couple lines explaining this spec? In particular I wasn't quite sure why
> "tau <= t" in the postcondition makes intuitive sense (I guess a suitable
> witness for t is the most recent timestamp in the input history tau_O).

Similarly as in the case of readPair, we're not guaranteed that readX
will return the values from the most recent time-stamp. Instead, readX
will return some value in the "interval" [\tau, \tau_O], where \tau is
the "input" other history, and \tau_O is the "output" other
history. Intuitively, after readX reads from x, but before it returns
the obtained value, \tau_O may grow due to other threads
interference. By requiring \tau <= t, we ensure that we won't get a
value from the history, which has "expired" before the call to
readX. We will clarify this point in future revisions.

> Figure 2, line 7, I like the way in which tau_1 no longer appears in this
> assertion, as it is subsumed by tau_2, which is a richer history. Nice.

Thanks.

> p.4, "labeled components". When a history is identified by a label l, one
> could think of the history as stored in a ghost memory cell whose address is
> l. Thus, instead of saying that l is a "label", you could say it is a "ghost
> memory location". (Some authors have also used the words "region" or "island"
> for a piece of ghost state identified by a unique address.)

This is a right intuition, so we will draw this analogy.

> p.4, "The self and other portions of any given label have to belong to a
> common PCM". What about the joint portion? Does it also have to belong to some
> PCM?

In general, no. Although in most of our examples the joint part has
been a PCM (most often a heap), the theory doesn't require it. The
intuition is that the joint component is not subject to self/other
split between threads.

> p.4, "different labels can use different PCMs". So the points-to assertions
> are implicitly parameterized with a PCM?

Yes, since a label uniquely determines a concurroid instance, and,
hence, the type of its PCM.

> p.4, "These three basic assertions can be combined by the usual propositional
> connectives [...]". Why does it make sense here to use ordinary conjunction
> instead of separating conjunction?

l -s-> a constrains the self portion of l to be a, but doesn't
constrain the "other" and "joint" portions of label l to be
empty. Symmetrically for l -j-> a and l -o-> a (see (13) and Figure 10
in the appendix of the longer version). Thus, each of the basic
assertions contains as its domain the full state of the label l. Since
the states of the basic assertions are not disjoint, the assertions
can't be conjoined by separating conjunction.  We have found this
choice to give us the shortest specs in practice.

> p.5, in the definition of "wr_x", the "other history" tau_O seems to appear
> out of nowhere (I mean, there is one occurrence of the metavariable tau_O,
> but it is not constrained by an assertion l |->^O tau_O). Puzzling.

We assume \tau_O to be always available from the corresponding
concurroid. In this particular case we need to refer to it in order to
instantly pick a fresh value of a timestamp as a maximum of timestamps
currently used in \tau_S and \tau_O plus one. It is also worth
mentioning that wiggly-arrow means that "other" field \tau_O remains
fixed (transitions are defined so that they never change the other
component, essentially defining the concurroid's Guarantee). We will
clarify this in future revisions.

> One thing that isn't clear to me at the end of Section 3 is that there is
> a certain mismatch between Sections 2 and 3. Throughout Section 2, triples
> of the form {P}c{Q} are used. Now, Section 3 reveals that in FCSL, triples
> really are quadruples of the form {P}c{Q}@U. So I assume Section 2 must be
> revisited with the idea that every triple in it is implicitly relative to
> the pair-snapshot concurroid, called "S" in the paper. Thus, the "real"
> spec of readPair is of the form {...} readPair() {...} @ S. Now, if I am
> a client who wishes to use readPair(), how much do I need to know about S?
> Do I need to have access to its concrete definition? (Hopefully not, since
> it reveals implementation details of the pair-snapshot data structure.) Do
> I need to treat S as an "abstract concurroid" whose definition is opaque?
> Or can I somehow "hide" S and perform my client-side reasoning in the empty
> concurroid? I wish this was clarified.

First of all, the @U component in Hoare quadruples of FCSL plays the
role of Rely/Guarantee and the Resource Invariant for a particular
concurrent data structure, as presented by [22]. It was omitted in
semi-formal specs in Section 2 for the sake of simplicity, since the
shape of the state (two pointers, x and y) and the "Rely" (two "write"
operations) were assumed to be intuitively clear.

In the formal FCSL reasoning, all "relevant" concurroids, whose state
is being affected or examined by the program being verified, should be
mentioned explicitly and concretely. The "irrelevant" concurroids can
be (and usually are) "framed away" by means of the "extend" rule (18).

The concern about "abstract concurroids" is answered in the first part
of the response.

> p.6, "Note that pop doesn’t deallocate [...]". If you modified the code of
> pop() to deallocate the node p, would your proof break? (I hope it would!)
> Where/why would it break? Is this explained later on in the paper? My guess is
> that 1- the Treiber concurroid doesn't allow deallocation (as noted in the
> paper); 2- if pop() used deallocate(), then its spec would need to mention
> P-entangled-T instead of just T; 3- but then certain assertions that appear in
> its proof would no longer be stable (not sure why).

Short answer: the Treiber concurroid is designed in such a way that it
doesn't have a "release" transition, so there is no way to write code
that operates with it and transfers ownership over some chunks of the
heap from its joint state anywhere else.

Long answer requires us to recall that the proof of the Treiber stack
specifications starts with defining the concurroid T and its "resource
invariant", which ties together a number of properties, in particular:

(1) Its overall self/other history is stacklike, complete and
continuous; (2) the "last" snapshot in the history corresponds to the
contents of the actual stack.

Next, *all* the transitions of the concurroid are shown to preserve
these invariants. Essentially, these properties together imply that
the stack data structure evolves "in a right way", without
experiencing the ABA problem. After formulating the transitions, one
should define actions, which tie the concurroid logic to the program
commands, such as write, CAS, etc (see Appendix C of the extended
version of the paper). A number of properties of such actions should
be proved, in particular, that they respect transitions and don't
break the invariant. 

Finally, one should give reasonably strong *stable* specs to the
actions (with respect to concurroid's transitions). Such spec for
'tryPush' can be read from the proof in Figure 4. The spec for
'tryPop' is similar. The proofs of these specs very much rely on the
implicit invariant that the pointers in the stack structure (except
'snt') *never* change their values.

Had we allowed the pop-transition de-allocate (e.g., by making it a
release-transition and entangling T with P), we could not, in
particular, ensure the stability of tryPop's precondition anymore (as
someone else could deallocate the pointer at the same time, change its
value, and push it back). And since this precondition is essential for
making use of the T's 'pop' transition, we wouldn't be able to use
'pop' anymore, because otherwise, in some cases depending on the
interference, it would break the concurroid invariant.

Allowing deallocation is possible (turning Treiber's stack into a
Michael's stack), but it amounts to redesigning the whole data
structure and reformulating its invariant.

> p.6, in the definition of the Treiber concurroid, why is the shared heap h_s
> described explicitly (i.e. as a union of several sub-heaps) instead of via a
> separation logic assertion (i.e. as a separating conjunction of several
> predicates, one for each sub-heap)? We seem to be losing some of the usual
> benefits of separation logic here. We end up using a first-order logic
> predicate list(p, l, h) instead of the usual separation logic predicate
> list(p, l).
> Similarly, why does (26) on p.7 define Arr_n(a,l,h), instead of
> separation-logic predicate Arr_n(a,l)?
> And why do we have to write "pv \mapsto^s h" instead of just writing
> a normal separation logic assertion that describes our private state?
> Again, we seem to be losing some readability (and compatibility with
> standard separation logic). Could this situation be improved?

These concerns are addressed in the first part of the response.

> p.6, why does completeness (no gaps in the history) not appear also in the
> pair-snapshot example? I suppose it is not necessary there.

History completeness is needed for client-side reasoning. Since we
didn't consider clients of readPair, we went for a simpler spec to
improve readability. For stacks we did build clients, and thus we
needed the continuity, in particular, to verify the spec of the
producer/consumer client and the sequential spec (23).

> Figure 4, the proof is clear, except of course the reader would like
> to know how one proves that tryPush admits this specification.

Indeed. The Coq files contain such proof (see treiber.v). We apologize
for omitting these details in the paper due to lack of space.

> p.7, "which is essentially an elaborated version of (1)". Perhaps you
> could introduce grb also in the precondition, and then argue that, up
> to an appropriate definition of the "abstract points-to" predicate that
> appears in (1), we *really* obtain (1).
> p.8, "Note also that the sentinel pointer is returned back to the private
> heap, along with the garbage heap". This seems a little too concrete in
> my eyes. Ideally I would like the proof of "exchange" to be independent
> of the implementation of Treiber's stack -- hence the client should not
> know that there is a sentinel pointer, a garbage heap, etc. It should
> only reason in terms of an abstract predicate that describe a Treiber
> stack. Could you do this? I suppose you can (but the module Treiber needs
> to export an operation new_stack() in addition to push() and pop()).

Certainly. However, abstractions of this sort are not considered in
this paper, as discussed in the first part of the response. We didn't
build such abstraction for stacks, but did for locks in [22].

> p.8, "To supply the intuition behind the proof, we first review how ordinary
> locks work with auxiliary state [...]". Could you explicitly give the Hoare
> triples (or quadruples) for lock and unlock? The informal description that
> follows is difficult to understand.

We will clarify it in future revisions. Right now, the definition of
such quadruples for lock/unlock can be found in page 9 of [22] (let us
refrain from putting it in ASCII here).

> p.8, you write "As in CSL [...]  a lock comes with a resource invariant I
> which relates the auxiliary state to the heap of the shared resource". But
> in CSL, I is just an assertion, which describes the shared resource, period.
> There is no built-in idea of an "auxiliary state" in the reasoning rules for
> locks, is there?

You're right, resource invariants in CSL follow Owicki-Gries and are
not explicitly parametrized by auxiliary state. Nevertheless, their
job *is* to relate auxiliary state to the heap of the shared
resource. One may say that the auxiliary state is "hardcoded" in the
invariant. This is one of the drawbacks of Owicki-Gries, as observed
in the introduction of the paper [19].

> If one were to implement coarseGrainedCombine(f, x) simply as a sequence
> of lock();f(x);unlock(), would one be able to prove exactly the same
> abstract specifications for coarseGrainedCombine and flatCombine?

Almost. The specification would be the same, modulo the NoReq conjunct
in (32) and the join with all "g_p[i]" components in (31), which would
not be present in the coarse-grained case, as they are artefacts of
the helping machinery. To provide truly *the same* specs, one would
need abstract predicates to hide these artefacts, but we can do that
in Coq.

> Footnote 7 on page 9 is cryptic. Exactly what kind of side effects is the
> function f allowed to perform? Can it alter some private state? Can it use
> concurrent data structures (other than the flat combiner at hand)? etc.
> I am somewhat lost.

We just meant, the spec doesn't require the function to be
sequential. The function can certainly alter private state, but it can
also allocate new concurroids via hiding, and fork children threads.

> Ideally one should explain how a new flat combiner is initialised,
> how each participating thread receives its own tid and its own proof
> of NoReq(tid). Ideally this machinery should be somehow abstracted
> away inside the FC module, which would provide only two operations
> new_flat_combiner() and flatCombine(fc, f, x)...  (Of course the
> paper is complex enough as it stands. This is just a suggestion for
> future work...)

This concern about abstract interfaces for concurroids has been
responded in the "short" part of the response above.

To elaborate a bit more, we would like to add that it is an
interesting point in general, what would be the *best* abstract
interface for, e.g., stack-like concurroids. For instance, some stacks
(e.g., Treiber's) admit an arbitrary number of threads, whereas some
others (e.g., our FC-stack or Michael's stack) work only with a
limited number of threads. Moreover, the memory footprint for
different implementations is going to be different (e.g., Treiber's
stack doesn't deallocate); that said, should the "abstract" interface
admit possible memory leaks after the stack has been deallocated?
While all these are important questions to be answered, we considered
them orthogonal for the work presented, and therefore, did not discuss
in the paper.

===[#68C]===

> [HOCAP/iCAP] present one spec that can be specialised to the obvious
> sequential spec, and also to the specification you give in the
> introduction (2). [Note this is allowing the client to specify the
> spec, not as you claim a necessary restriction on all clients].  Can
> you provide one spec that is that general?  You show you can
> specialise to the sequential spec, but not to (2).

The "weak" specification (2) for stacks, whose all elements satisfy
the predicate P, can be obtained by making an assumption about the
self and other-contributions to the history (i.e., elements pushed by
the thread itself and its environment), namely, that the pushed
elements would always satisfy P. Out of this assumption, since pop's
spec (21) essentially says that if an element has been popped, then it
must have been pushed previously by the same or some other thread
(which follows from the predicates 'complete' and 'stacklike' defined
on the stack histories), we can infer that *if* all pushed and
initially present elements in the stack satisfied P, than any popped
element satisfies P as well.

The *if* can be removed by means of hiding, which allows one to limit
the interference and account for the contributions of all interfering
threads to the data structure, as illustrated by the producer/consumer
example, therefore, in this case making it possible to check that *no*
elements falsifying P were pushed. Indeed, to remove the *if* without
hiding, one needs the extensions that we alluded to wrt "make_atomic"
when discussing related and future work in Section 6.

===[#68D]===

[No questions were asked.]


\section{Discussion}
%\section{Client-side reasoning}
\label{sec:clients}

%\gad{Section 4 should emphasize that we are hiding colors, end-points,
%  and whatever `` internal'' aspects of the concurroid in client
%  reasoning. This might require to connet with the proof outline from
%  Figure~\ref{fig:weird:code} in the appendix. We should say that this
%  internal only ``leak'' through the definition/instantiations of
%  $\jleq$.}

We already argued in Section~\ref{sc:formal} that the Hoare triples
from Figure~\ref{fig:specs} capture precisely what linearizability
would be used for, namely that the operations of the snapshot object
can be sequenced. The triples do so without the intermediary
sequential specifications for {\tt write} and {\tt scan}, and the
attending simulation proofs.  In this section, we argue that our
approach via Hoare logic can still do a bit more, specifically in the
cases of client side reasoning, and reasoning about parallel
composition.

By relying on FCSL, we immediately inherit the separation logic
mechanism for reasoning about programs with nested parallel
composition (i.e., dynamic, well-bracketed, forking and joining). We
refer the interested reader to the Appendix~\ref{sc:background} for a
brief background on FCSL, and the separation-logic style inference
rule for parallel composition that requires that program state, real
and auxiliary, satisfies the properties of a Partial Commutative
Monoid, or PCM (and indeed, our histories form a PCM under the
operation of disjoint union, with the empty history as a unit). This
gave us a thread-local way to reason about programs, via local
variables such as $\histS$ and $\histO$, rather than relying on global
abstractions, such as \emph{thread-id}s, to specify the behavior of
each thread.  This is in contrast to linearizability, whose very
definition requires identifying threads by thread-ids, thus focusing
on programs that are a top-level parallel composition of a fixed
number of sequential threads, but not providing convenient
abstractions for reasoning about nested parallel compositions.

%As a first point, we argue that the pre- and postcondition ascribed to
%{\tt write} and {\tt scan} in Section~\ref{sc:formal} are
%\emph{principal}, in that they can be used in larger program contexts
%without modification. This is not the case in most other verification
%methods, where programs, once verified, typically still have to be
%refactored wrt.~auxiliary state and code \emph{on a per-context
%  basis}~\cite{Owicki-Gries:CACM76,Jacobs-Piessens:POPL11}. By using
%\emph{local} variables such as $\histS$ and $\histO$ to name the
%per-thread history, we avoid the need for refactoring. Such locality
%is supported by the FCSL inference rule for parallel
%composition~\cite{LeyWild-Nanevski:POPL13,Nanevski-al:ESOP14}. The
%rule is somewhat unusual, but please see Appendix~\ref{sc:background}
%for a brief description. What matters, however, is that reasoning in
%clients is done strictly out of the specs of {\tt write} and {\tt
%  scan}. Notice that, while these expose the existence of the logical
%ordering $\jleq$ and how some individual events may be related in it,
%they \emph{do not} expose the actual definition of $\jleq$ in terms of
%colors, or any other internal of the auxiliary state and code. Other
%snapshot implementations can provide their own definition of $\jleq$.

As a brief example of reasoning about parallel composition, it is
possible to prove that the program
%
$ 
P_1 = {\mathtt{write}}\ (x, 1) \parallel {\mathtt{write}}\ (y, 2)
$
%
satisfies the spec which says that two events are executed, in an
unspecified order. Then we can reason about a larger program, say
$
  P_2 = P_1; {\mathtt{write}}\ (x, 3)
$
out of that spec, to prove that $P_2$ executes three events, with the
write of $3$ appearing last. 
%
Moreover, the \emph{substitution principle} holds; that is, the proof
remains valid, even if we replace $P_1$ by another program, say
%
$
P'_1 = {\mathtt{write}}\ (x, 1); {\mathtt{write}}\ (y, 2)
$
which satisfies a stronger spec (explicitly ordering the two events),
but which \emph{can be weakened} to the spec of $P_1$ by forgetting the
ordering by means of strengthening the precondition and weakening the
postcondition, as customary in Hoare logic. Thus, our client proofs
\emph{can ignore} the internal thread-structure of component programs.

\input{readpair}

The substitution principle can be pushed further. In particular, we
can use a different snapshot algorithm, without modifying the proofs
of $P_1$, $P_2$, $P'_1$ or any other client, as long as {\tt write}
and {\tt scan} satisfy the expected specs.
%
We have confirmed this property on the toy example given in
Figure~\ref{fig:readpair} (we present only {\tt scan}, as {\tt write}
is trivial)~\cite{Sergey-al:ESOP15}. In this example, the snapshot
structure consists of pointers $x$ and $y$ storing tuples $(c_x, v_x)$
and $(c_y, v_y)$, respectively. $c_x$ and $c_y$ are the payload of $x$
and $y$, whereas $v_x$ and $v_y$ are version numbers, internal to the
structure. Writes to $x$ and $y$ increment the version number. {\tt
  Scan} reads $x$, $y$ and $x$ again, in succession, but avoids
snapshot inconsistency by restarting if the two version numbers of $x$
differ. The definition of $\jleq$ used to satisfy the specs equals the
real time one, as no dynamic reordering is needed.

%\gad{Why are we not calling read-pair by it's name?}
%%
%\an{Well, because we're trying to make the parallel with the Jayanti's
%  code. By calling it {\tt scan}, the connection is immediately
%  made. Speaking of names, I'm more concerned that we name with {\tt
%    write} two different things. The primitive memory operation should
%  probably be renamed into $x := v$ or {\tt assign}.}
%%
%\gad{I understand. But I was refering to the algorithm and not the
%  methods.}

\begin{comment}
\begin{enumerate}
\item Show some silly clients, to illustrate how the specs work. 

  \gad{Let's see what we have right now:}  
  \begin{itemize}
  \item[i] One thread example: show that write x 3; write y 5; scan ()
    allows us to infer that the ordering of x and y was preserved and
    furthermore the timestamps of the return value would allows us to
    infer when the interfering threads happened in time, compared to
    our contributions.

  \item[ii] two sequential scans, and a proof that whatever the second
    scanner returned was not in the visible results of the first one.

  \item[iii] Some clients with $\mathbf{hide}$?. \gad{At some point we
    said that we should try to use hide as a leverage against Khyza et
    al.}
  \end{itemize}

\gad{The first two are the ones I'm working on right now to test the
  new set of rules}.
  
\item Emphasize that the client reasoning depends solely on the API
  for scan and write.
\item In particular, we could have another implementation of snapshot,
  and the same spec can be given. Quickly describe readpair. \is{It
    will be easier if it makes an appearance in the intro.} Point to
  the previous paper, and show which spec we gave there. Argue that by
  rule of consequence, this can trivially be coerced into the spec we
  have here.
\item Probably again avoid talking about FCSL background. When
  describing the proof outlines for the clients, talk your way around
  the splitting, zigzagging, hiding (if we end up using
  hiding). \is{In my talks I typically say it's the way to restrict
    the interference, and the concurrency crowd is happy with it. For
    instance, Noam's last time reaction to this was like ``oh, sure,
    you just assume that your all threads are just t1 and t2, that's a
    trivial assumption to enforce!''}
\end{enumerate}

\end{comment}

